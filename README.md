# 人人都是产品经理 AI 专栏阅读

一个用于抓取人人都是产品经理（woshipm.com）AI 专栏文章数据的 Python 爬虫项目，提供 Web 界面管理，支持定时自动更新、手动更新和 AI 文章评分。

## 项目简介

该项目会抓取文章的标题、链接、描述、发布时间、字数等信息，并存储到 SQLite 数据库中。提供友好的 Web 界面，支持文章管理、筛选、已读标记、笔记记录和 AI 评分等功能。

主要功能：自动抓取人人都是产品经理网站AI专栏的新文章，并利用大模型多维度评分；浏览文章列表时，根据标题、介绍、评分信息标记是否阅读；阅读文章后记笔记。

## 技术栈

- **语言**: Python 3.13.2
- **Web 框架**: Flask
- **依赖库**:
  - `requests`: HTTP 请求
  - `beautifulsoup4`: HTML 解析
  - `sqlite3`: SQLite 数据库（Python 标准库）
  - `openai`: 大模型 API 调用
  - `schedule`: 定时任务调度

## 项目结构

```
woshipm-ai-read/
├── app.py              # Flask Web 应用主程序
├── articles.db         # SQLite 数据库文件
├── requirements.txt    # Python 依赖列表
├── .env                # 环境变量配置
├── static/
│   └── css/
│       └── style.css   # Web 界面样式
└── templates/
    └── index.html      # Web 界面模板
```

## 功能说明

### 主要功能

1. **抓取文章列表**: 从人人都是产品经理的 AI 专栏抓取文章列表
2. **文章详情解析**: 访问每篇文章的详情页，提取以下信息：
   - 标题、链接、描述
   - 发布时间、文章字数
   - 文章完整内容
3. **数据存储**: 将文章信息存储到 SQLite 数据库 `articles.db`
4. **去重处理**: 根据文章链接去重，避免重复抓取
5. **更新模式**: 支持两种模式
   - `mode = 0`: 更新所有文章（包括已存在的）
   - `mode = 1`: 仅抓取新增文章（默认）
6. **AI 评分**: 使用大模型对文章进行多维度评分（内容质量、实用性、创新性等）
7. **Web 管理界面**: 提供友好的 Web 界面管理文章

### Web 界面功能

- 📋 查看文章列表及详细信息（标题、时间、字数、评分）
- ✅ 勾选复选框标记文章为已读/未读
- 🔗 点击文章标题在新标签页打开原文
- 📝 笔记功能：为文章添加、编辑、删除笔记
- 🔍 筛选功能：全部文章/未读文章/已读文章
- 📊 实时统计：显示总数、已读数、未读数
- 🔄 立即更新：抓取前 3 页最新文章
- 📥 补齐历史数据：抓取多页历史文章（可设置日期范围）
- ⏰ 服务状态：显示下次自动更新时间
- 🎯 AI 评分：对文章进行智能评分和评价

### 数据库结构

`articles` 表包含以下字段：
- `link`: 文章链接（主键）
- `title`: 文章标题
- `time`: 发布时间
- `desc`: 文章描述
- `length`: 文章字数
- `read`: 是否已读（0: 未读, 1: 已读）
- `content`: 文章完整内容
- `score`: AI 评分总分
- `score_details`: AI 评分详情（JSON 格式）

`notes` 表包含以下字段：
- `id`: 笔记 ID（主键）
- `article_link`: 关联的文章链接
- `content`: 笔记内容
- `created_at`: 创建时间
- `updated_at`: 更新时间

## 快速开始

### 1. 安装依赖

```bash
pip install -r requirements.txt
```

### 2. 配置环境变量

创建 `.env` 文件并配置以下变量：

```env
# 大模型 API 配置（用于 AI 评分功能）
LLM_API_KEY=your_api_key_here
LLM_API_BASE=https://api.openai.com/v1
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.3
```

### 3. 启动服务

#### 前台运行（开发模式）

```bash
python3 app.py
```

#### 后台运行（生产模式）

```bash
nohup python3 app.py > app.log 2>&1 &
```

### 4. 访问 Web 界面

打开浏览器访问: http://localhost:5000

## 使用指南

### 查看服务状态

```bash
# 查看进程
ps aux | grep app.py | grep -v grep

# 查看日志
tail -f app.log
```

### 停止服务

```bash
pkill -f app.py
```

### Web 界面操作

#### 立即更新

点击"🔄 立即更新"按钮，抓取前 3 页最新文章。

- **功能说明**: 抓取前 3 页最新文章
- **适用场景**: 日常使用，快速获取最新文章
- **自动评分**: 勾选"自动评价新增文章"后，抓取完成后会自动对最近 7 天的未评分文章进行评分

#### 补齐历史数据

点击"📥 补齐历史数据"按钮：

1. 输入起始日期（格式：YYYY-MM-DD，例如：2025-12-01）
   - 留空则不限制日期，抓取所有历史文章
2. 输入最大抓取页数（默认：100）
3. 确认后开始后台抓取

- **功能说明**: 抓取多页历史文章（可设置日期范围）
- **适用场景**: 首次使用或数据缺失时
- **自动评分**: 勾选"自动评价新增文章"后，抓取完成后会自动对最近 7 天的未评分文章进行评分

#### AI 评分

点击文章卡片上的"AI 评分"按钮，使用大模型对文章进行多维度评分。

评分维度包括：
- 信息增量
- 逻辑严密性
- 可理解性/易读性
- 结构组织
- 行动启发

评分完成后，可以点击"查看评分详情"查看详细的评分结果和评价。

## 服务特性

- **定时更新**: 每天下午 15:00 自动更新数据
- **立即执行**: 启动时立即执行一次数据抓取
- **手动更新**: Web 界面支持随时手动触发更新
- **增量更新**: 仅抓取新增文章，避免重复
- **日志记录**: 所有操作记录到 app.log
- **AI 评分**: 支持使用大模型对文章进行智能评分

## 开发约定

- **请求间隔**: 每次请求之间随机等待 3-5 秒，避免被封 IP
- **超时设置**: 请求超时时间为 10 秒
- **User-Agent**: 使用浏览器 User-Agent 模拟真实用户访问
- **错误处理**: 对网络请求和解析错误进行异常捕获，不影响整体爬取流程

## 注意事项

- 该项目仅用于学习和研究目的
- 请遵守网站的 robots.txt 规则和服务条款
- 爬取频率已做限制，但仍需注意不要对目标网站造成过大负担
- AI 评分功能需要配置有效的 API Key
- 首次启动会立即执行一次数据抓取
- 服务会持续运行，直到手动停止
- Web 服务默认运行在 5000 端口
